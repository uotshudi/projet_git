{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787652dc-1726-4169-8d0d-a7b3f751134e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importation des librairies \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e35242a-ca2f-4611-bb48-c869600d1758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import models\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences \n",
    "nltk.data.path.append(\"/home/jovyan/teams/syne_data/Commun/NLTK\")\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import models \n",
    "import collections\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "# Ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "#import sentencepiece\n",
    "#from numba import jit, njit\n",
    "import torch  \n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59009db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5976a33-bb4c-4c31-a316-4192a8aef134",
   "metadata": {
    "tags": []
   },
   "source": [
    " ## Importation de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9bc6890-c053-47fd-9a41-05b8fd1641c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jovyan/workspaces/syne_drh/Data2023/EAC/Entretien_Annuel_de_Competence_2022.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14684\\3775429636.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/home/jovyan/workspaces/syne_drh/Data2023/EAC/Entretien_Annuel_de_Competence_2022.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jovyan/workspaces/syne_drh/Data2023/EAC/Entretien_Annuel_de_Competence_2022.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/jovyan/workspaces/syne_drh/Data2023/EAC/Entretien_Annuel_de_Competence_2022.csv\",delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b6ed109-54dd-4f26-9e2b-be8629f45589",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14684\\169168403.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef0c1554-8e1b-4ea6-abb4-dfabde94cc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f740486d-d524-4443-806b-3c6d11caed92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>library_name</th>\n",
       "      <th>version</th>\n",
       "      <th>bundle_name</th>\n",
       "      <th>support_level</th>\n",
       "      <th>run_deploy</th>\n",
       "      <th>key_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accelerate</td>\n",
       "      <td>0.*</td>\n",
       "      <td>DL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Python library is designed to optimize and acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accelerate</td>\n",
       "      <td>0.*</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Python library is designed to optimize and acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airflow</td>\n",
       "      <td>2.8.0</td>\n",
       "      <td>AFL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>schedule and monitor workflows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anytree</td>\n",
       "      <td>2.*</td>\n",
       "      <td>MIN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dataviz to plot decision tree, nodes and links</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apache-airflow-providers-vertica</td>\n",
       "      <td>2.*</td>\n",
       "      <td>AFL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>airflow package for vertica provider</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       library_name version bundle_name  support_level  \\\n",
       "0                        accelerate     0.*          DL              0   \n",
       "1                        accelerate     0.*         NLP              0   \n",
       "2                           airflow   2.8.0         AFL              0   \n",
       "3                           anytree     2.*         MIN              1   \n",
       "4  apache-airflow-providers-vertica     2.*         AFL              0   \n",
       "\n",
       "   run_deploy                                          key_words  \n",
       "0           0  Python library is designed to optimize and acc...  \n",
       "1           0  Python library is designed to optimize and acc...  \n",
       "2           0                     schedule and monitor workflows  \n",
       "3           0     dataviz to plot decision tree, nodes and links  \n",
       "4           0               airflow package for vertica provider  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b4cfc1-5ad6-4ac4-a3da-7def5f64ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb612b0-4222-47de-8ee5-513d3c109887",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"On a \"+str(len(data[\"Matricule de l'évaluateur\"].unique()))+\" évaluateurs et \"+\n",
    "str(len(data[\"Matricule de l'évalué\"].unique()))+\" évalués\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ade051-04f5-48df-a404-ce6729840a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_com(colonne,min_count,max_length):\n",
    "    c = collections.Counter(data[colonne])\n",
    "    values, counts = zip(*c.most_common())\n",
    "    most_common = []\n",
    "    i = 0\n",
    "    while i<len(values) and (type(values[i])!=str or (counts[i]>min_count and len(values[i])<max_length)) :\n",
    "        most_common.append(values[i])\n",
    "        i+=1\n",
    "    return(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883730f-4228-4b01-afb3-be2de90ab54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_most_common_com(\"QVT : Commentaire du collaborateur\",1,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c62463c-44cf-41a4-9d25-6879862b8431",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyse de sentiment pour QVT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf2061-6dda-4b3e-8b6a-87ee2ba85655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[[\"Matricule de l'évalué\",\"Matricule de l'évaluateur\",\"Commentaire général entretien : Collaborateur\"]]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0a50c-ea74-4c0c-969b-10a1b0e0cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train =  train.drop_duplicates(subset=[\"Matricule de l'évalué\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bceb85-741a-46e9-af80-527e760eaa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemple = train.iloc[50][\"Commentaire général entretien : Collaborateur\"]\n",
    "print(exemple)\n",
    "re.split('\\n.', exemple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b0ca6-0133-4317-94df-5dd94a77b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=stopwords.words('french')\n",
    "A.extend(['X', 'x','xxx','xx','ras','cet', 'ete', 'tres', 'non', 'oui', 'Non', 'Oui', 'a', 'A', 'tout', 'pu', 'faire', 'etre', 'sein',\n",
    "         'chez', 'lors', 'car', 'va', 'ainsi', 'fait', 'cette', 'afin', 'cela', 'avoir', 'cette', 'doit', 'avant', 'alors', \n",
    "         'autre', 'chaque', 'tel', 'tels', 'tellement', 'font', 'bien', 'peu', 'aussi', 'temps', 'tant', 'toute', 'toutes', 'ci', \n",
    "         'bon', 'alors', 'au', 'aucuns', 'aussi', 'autre' ,'avant', 'avec' ,'avoir', 'bon' ,'car', 'ce', 'ces', 'ceux', 'chaque',\n",
    "          'comme',\n",
    "         'comment', 'dans', 'des', 'du', 'dedans','dehors', 'depuis', 'devrait', 'doit', 'donc', 'dos', 'début', 'elle',\n",
    "          'elles', 'en', 'encore',\n",
    "          'essai', 'est', 'et', 'eu',  'fait', 'faites', 'fois', 'font', 'hors', 'ici', 'il', 'ils','ca',\n",
    "         'je', 'juste' ,'la', 'le', 'les', 'leur', 'là', 'ma' ,'maintenant', 'mais', 'mes', 'mien', 'moins', 'mon', 'mot', 'même','egalement'\n",
    "          'ni', 'nommés', 'notre' ,'nous', 'ou', 'où', 'par' ,'parce' ,'pas', 'peux', 'cas',\n",
    "          'peut', 'peu', 'plupart', 'pour', 'pourquoi', 'quand', 'que', 'quel' ,'quelle', 'quelles', 'quels' ,'qui', 'sa', 'sans', 'ses', 'seulement', 'si',\n",
    "          'sien', 'son', 'ont' ,'sous', \n",
    "          'soyez' ,'sujet', 'sur', 'ta', 'tandis', 'tellement' ,'tels', 'tes', 'ton', 'tous', 'tout', 'trop', 'tres', 'tu', 'voient', 'vont', 'votre', 'vous',\n",
    "         'vu', 'ça', 'étaient', 'etat', 'étions', 'ete', 'etre', 'entre', 'beaucoup', 'jour', 'annees','annee' 'plus', 'trouve', 'meme', 'dont', 'vue', 'nan','toujours','concernant','plus'])\n",
    "  \n",
    "def enleve_stop_words(text):\n",
    "    words = text.split(\" \")\n",
    "    words_net= [item for item in words if item not in A] \n",
    "    return(\" \".join(words_net))\n",
    "\n",
    "def preprocessing(text,stop_words = True):\n",
    "    if isinstance(text, str):\n",
    "        text = str(text)\n",
    "        #lowercase\n",
    "        text = text.lower()\n",
    "        #accents and punctuations\n",
    "        text = re.sub(\"\\d+\", \" \", text) #numbers normalization\n",
    "        if stop_words:\n",
    "            text = enleve_stop_words(text)\n",
    "        text = re.sub('[éèê]', \"e\", text) #accents removal\n",
    "        text = re.sub(\"[.,;:!?]\", \" \", text)\n",
    "        text = re.sub(\"[|{}\\[\\]()«»/]\", \" \", text)\n",
    "        text = re.sub(\"[“”]\", \" \", text)\n",
    "        text = re.sub(\"'\", \" \", text) \n",
    "        text = re.sub(\"\", \" \", text) \n",
    "        text = re.sub('\"', \" \", text)\n",
    "        text = re.sub('[+-]', \" \", text)\n",
    "        text = re.sub('[=*/]', \" \", text)\n",
    "        text = re.sub(\"ô\", \"o\", text)\n",
    "        text = re.sub(\"°\", \"\", text)\n",
    "        text = re.sub(\"\\x80\", \"\", text)\n",
    "        text = re.sub(\"[«»€$%;:.,?!=()+&@*%^¨~#><]{1,}\", \" \", text)\n",
    "        text = re.sub(\"[\\/]{1,}\", \" \", text)\n",
    "        text = re.sub(\"'\", \" \", text)\n",
    "        text = re.sub('\"', \" \", text)\n",
    "        #Symbols\n",
    "        text = re.sub(\"[€%$£]\", \"\", text)\n",
    "        #End of lines and parahraph breaks\n",
    "        text = re.sub('\\r\\n', \" \", text)\n",
    "        text = re.sub('\\n', \" \", text) #end of line removal\n",
    "        #white spaces\n",
    "        text = re.sub('\\s+', \" \", text) #white space removal\n",
    "        text = text.rstrip(\" \") #à droite\n",
    "        text = text.lstrip(\" \") #à gauche\n",
    "        if stop_words:\n",
    "            text = enleve_stop_words(text)\n",
    "    else:\n",
    "        return('')\n",
    "    return  text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc16fd-68ef-44ad-a051-fc865febd31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[\"QVT : Commentaire du collaborateur\"] = train[\"QVT : Commentaire du collaborateur\"].apply(lambda x:preprocessing(x,stop_words=False))\n",
    "train[\"clean_commentaire\"] = train[\"Commentaire général entretien : Collaborateur\"].apply(lambda x:preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec92d2-7fdd-4fcc-b1f8-5777e019d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_com(colonne,min_count,max_length):\n",
    "    c = collections.Counter(train[colonne])\n",
    "    values, counts = zip(*c.most_common())\n",
    "    most_common = []\n",
    "    i = 0\n",
    "    while i<len(values) and (type(values[i])!=str or (counts[i]>min_count and len(values[i])<max_length)) :\n",
    "        most_common.append(values[i])\n",
    "        i+=1\n",
    "    return(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa0f73-d039-4571-b7dc-3d7016b262c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_most_common_com(\"clean_commentaire\",1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b299d454-5f66-4655-bf21-cc5079170ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train[\"clean_commentaire\"] != '') &\n",
    "          \n",
    "          (train[\"clean_commentaire\"] != 'rien ajouter') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf03f1-935e-49b1-b870-3393492e3394",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['temp_list'] = train[\"clean_commentaire\"].apply(lambda x:enleve_stop_words(x)).apply(lambda x:str(x).split())\n",
    "mots_insignifactif = [\"entretien\",\"annee\",\"mission\",\"echange\"]\n",
    "top = Counter([item for sublist in train['temp_list'] for item in sublist if item not in mots_insignifactif ])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Common_words','count']\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32508ec6-ab8c-49dc-a752-031fdf46c8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', \n",
    "             width=700, height=700,color='Common_words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c4f72-c25e-4ba1-a741-c2b9e61ff31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab41e3de-1072-42e4-93e9-263c03e49fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(top)\n",
    "# Afficher le nuage de mots\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1166f2d-e843-47b0-848c-08c6302915f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\", disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d02851-2af1-47ee-ba42-8c22159c7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emmebding(sentence):\n",
    "    tokenized_sentence = tokenizer.tokenize(sentence)\n",
    "    encoded_sentence = tokenizer.encode(tokenized_sentence)\n",
    "    encoded_sentence = torch.tensor(encoded_sentence).unsqueeze(0)\n",
    "    embeddings = camembert(encoded_sentence).last_hidden_state.mean(dim=1)\n",
    "    return(embeddings[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e972ee5-9823-4737-829b-93c89d0cb434",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"que est ce que tu penses de charge de travail ?\",\n",
    "             \"que est ce que tu penses de l'organisation du travail ?\",\n",
    "             \"tu peux équilibrer entre vie privee et vie professionnelle ? \",\n",
    "             \"que est ce que tu penses de la déconnexion de travail?\",\n",
    "             \"que est ce que tu penses de ton salaire?\"]\n",
    "\n",
    "emmebding_themes = [get_emmebding(questions[i])  for i in range(5)]\n",
    "def get_similarity(sentence):\n",
    "    emmebding = get_emmebding(sentence)\n",
    "    similarities = [1-cosine(emmebding_themes[i], emmebding) for i in range(5)]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_probabilities = scaler.fit_transform(np.array(similarities).reshape(-1,1))\n",
    "    return(scaled_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ea4fc-bfb6-49a6-b114-7095be9a0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence =\"L'organisation au sein de l'equipe est rodee, on nous laisse une autonomie et travailler en toute autonomie avec un soutien de managers si besoin.Je me suis adaptee au rythme du teletravail\"\n",
    "get_similarity(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdddfba-39e1-4a2e-b260-004210a9f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Définir la fonction pour extraire les mots avant \"permet\"\n",
    "def extraire_mots_avant_permet(liste_de_mots):\n",
    "    mots_avant = []\n",
    "    for i in range(len(liste_de_mots)):\n",
    "        if i >= 1 and liste_de_mots[i] == 'entretien':\n",
    "            mots_avant.append(liste_de_mots[i - 1])\n",
    "    return mots_avant\n",
    "\n",
    "# Appliquer la fonction aux commentaires\n",
    "liste_mots_avant = train[\"temp_list\"].apply(extraire_mots_avant_permet)\n",
    "\n",
    "# Compter le nombre d'occurrences de chaque mot\n",
    "compteur_mots_avant = Counter([mot for liste in liste_mots_avant for mot in liste])\n",
    "temp = pd.DataFrame(compteur_mots_avant.most_common(10))\n",
    "temp.columns = ['Common_words','count']\n",
    "# Créer le premier graphique\n",
    "fig1 = px.bar(temp, x=\"count\", y=\"Common_words\", title='Mots avant \"entretien\"', orientation='h',\n",
    "              width=600, height=400, color='Common_words')\n",
    "\n",
    "# Définir la fonction pour extraire les mots après \"permet\"\n",
    "def extraire_mots_apres_permet(liste_de_mots):\n",
    "    mots_apres = []\n",
    "    for i in range(len(liste_de_mots)):\n",
    "        if i < len(liste_de_mots) - 1 and liste_de_mots[i] == 'entretien':\n",
    "            mots_apres.append(liste_de_mots[i + 1])\n",
    "    return mots_apres\n",
    "\n",
    "# Appliquer la fonction aux commentaires\n",
    "liste_mots_apres = train[\"temp_list\"].apply(extraire_mots_apres_permet)\n",
    "\n",
    "# Compter le nombre d'occurrences de chaque mot\n",
    "compteur_mots_apres = Counter([mot for liste in liste_mots_apres for mot in liste])\n",
    "temp = pd.DataFrame(compteur_mots_apres.most_common(10))\n",
    "temp.columns = ['Common_words','count']\n",
    "# Créer le deuxième graphique\n",
    "fig2 = px.bar(temp, x=\"count\", y=\"Common_words\", title='Mots après \"permet\"', orientation='h',\n",
    "              width=600, height=400, color='Common_words')\n",
    "\n",
    "# Créer un subplot avec les deux graphiques côte à côte\n",
    "from IPython.display import HTML\n",
    "fig1_html = fig1.to_html(full_html=False, default_height=400, default_width=450)\n",
    "fig2_html = fig2.to_html(full_html=False, default_height=400, default_width=450)\n",
    "HTML(f'<table><tr><td>{fig1_html}</td><td>{fig2_html}</td></tr></table>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6924e3-ecd2-4b2e-a4f1-f3d8b45919c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tester les modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339f49be-ba20-4e84-b327-38f928ac0ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    try:\n",
    "        text = text.lower()\n",
    "        #text = re.sub('[éèê]', \"e\", text) #accents removal\n",
    "        #Symbols\n",
    "        text = re.sub(\"[€%$£]\", \"\", text)\n",
    "        #End of lines and parahraph breaks\n",
    "        text = text.rstrip(\" \") #à droite\n",
    "        text = text.lstrip(\" \") #à gauche\n",
    "        text = re.sub('\\s+', \" \", text)\n",
    "        A = stopwords.words('french')\n",
    "        words = text.split(\" \")\n",
    "        words_net= [item for item in words if item not in A] \n",
    "        text = \" \".join(words_net)\n",
    "        return(text)\n",
    "    except:\n",
    "        return('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07f112-71aa-44c9-bd91-52ba057a3c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c3cba1-494e-49d3-8f03-42c479395bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = pd.read_csv(\"data/Echantillonnage_supérvisé.csv\", sep = \";\",encoding='ISO-8859-1')\n",
    "sample_test = sample_test[[\"Matricule de l'Ã©valuÃ©\",\"Commentaire gÃ©nÃ©ral entretien : Collaborateur\",\"Vrai score entretien\"]]\n",
    "sample_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e794006-e5de-48f5-975c-09abaafc0216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, pipeline\n",
    "\n",
    "tokenizerRRR= AutoTokenizer.from_pretrained(\"/home/jovyan/teams/syne_data/Commun/sentiment_analysis_transformer/models/tokenizer/\")\n",
    "\n",
    "modelLLL = TFAutoModelForSequenceClassification.from_pretrained(\"/home/jovyan/teams/syne_data/Commun/sentiment_analysis_transformer/models/TFAutoModelForSequenceClassification/\") \n",
    "\n",
    "nlpYOU_1= pipeline('sentiment-analysis', model=modelLLL, tokenizer=tokenizerRRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0849925-7357-4a2e-bfcc-adf3a5597f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_score_1(text):\n",
    "    try:\n",
    "        result = nlpYOU_1(text)[0]\n",
    "        label = result.get(\"label\")\n",
    "        score = result.get(\"score\")\n",
    "        txt_return = label + \":\" + str(score)\n",
    "        return txt_return\n",
    "    except:\n",
    "        return \"erreur: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416ff97-796c-4dba-971a-64da8748f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = pd.read_csv(\"data/Echantillonnage_supérvisé.csv\", sep = \";\",encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30734c4d-ea35-4f90-9d95-61833eb1c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = sample_test[[\"Matricule de l'Ã©valuÃ©\",\"QVT : Commentaire du collaborateur\",'Vrai score QRV']]\n",
    "sample_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1cf6c1-5ea1-4500-bb10-a318e3db856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train[train[\"Matricule de l'évalué\"].isin(sample_test[\"Matricule de l'Ã©valuÃ©\"])]\n",
    "sample = sample.drop(\"temp_list\",axis=1)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67252de9-067a-4002-ba49-dcfaf7c9979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample[\"score\"] = sample[\"Commentaire général entretien : Collaborateur\"].apply(lambda x : get_label_score_1(preprocessing(x)))\n",
    "sample[['labl','score']]= sample.score.str.split(':',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cf8944-eeda-4229-ab53-191a16ceb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca0a7f-1048-403d-8c3e-af384ffaba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"true score\"] = sample[\"Matricule de l'évalué\"].apply(lambda x:sample_test[sample_test[\"Matricule de l'Ã©valuÃ©\"]==x][\"Vrai score QRV\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115914e-603f-425c-aa1d-3fc0b094148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4783ff0b-7cb3-48b8-85a0-073a865e7335",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['score'] = pd.to_numeric(sample['score'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26815cc0-1a9f-4c13-97ef-0afcaf34ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['level'] = pd.qcut(sample['score'],5, labels=[1, 2, 3,4,5])\n",
    "score = sample[\"true score\"].values\n",
    "level = sample[\"level\"].values\n",
    "c = 0 \n",
    "for i in range(len(score)):\n",
    "    if np.abs(score[i]-level[i])<=1:\n",
    "        c+=1\n",
    "print(c/len(score))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(score,level)\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Vraies étiquettes')\n",
    "plt.title('Matrice de Confusion pour le commentaire de colaborateur',fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c997bb-fb63-41ac-afa2-53fae3cbaff5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tester modèle 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dfc6d6-cfa4-4f9b-8f07-982c51394a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, pipeline\n",
    "tokenizerRRR= AutoTokenizer.from_pretrained(\"models/sentiment_analysis\" )\n",
    "modelLLL = TFAutoModelForSequenceClassification.from_pretrained(\"models/sentiment_analysis\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef33c84-a334-493b-b842-1055459bca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpYOU = pipeline(\"text-classification\",model=modelLLL, tokenizer=tokenizerRRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e12cc-0117-404d-90d2-2ad5ebcb7334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def get_proba(text):\n",
    "    inputs= tokenizerRRR(text,return_tensors=\"tf\")\n",
    "    outputs = modelLLL(**inputs)\n",
    "    logits = outputs.logits\n",
    "    return(np.array(tf.nn.softmax(logits))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da28d2-3ae6-43d4-9565-7599e93ee91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_proba(\"Alad'2 est clairement le meilleur film de l'année 2018.\")) # POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf251ca-c782-4251-9cc3-acce84dbbed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlpYOU(\"Alad'2 est clairement le meilleur film de l'année 2018.\")) # POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d1cc03-b91b-4947-9ce1-0de288caa75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(text):\n",
    "    if text == '':\n",
    "        return(None)\n",
    "    else : \n",
    "        t = nlpYOU(text)\n",
    "        return(int(t[0]['label'][0]))\n",
    "    #t = get_proba(text)\n",
    "    #return(sum([t[i]*(i+1) for i in range(5)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd72d90-a184-48ea-91d7-51777ccc159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558991e8-a3f6-4e48-96b6-493c4e000362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22971911-4761-45fa-84bb-f899b0fadab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = sample[\"Commentaire général entretien : Collaborateur\"].apply(lambda text:get_score(preprocessing(text))).values\n",
    "score = sample[\"true score\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde3504c-3fca-49e3-8a2b-352e3705d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0 \n",
    "for i in range(len(score)):\n",
    "    if np.abs(score[i]-level[i])<=1:\n",
    "        c+=1\n",
    "print(c/len(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b96ad5-f7a9-4250-96d4-1c686fa2580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(score,level)\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Vraies étiquettes')\n",
    "plt.title('Matrice de Confusion pour le commentaire de colaborateur',fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a11223-b403-4f70-b2c4-6c16e0e9dac6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### tester modèle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f6b29c-44cb-4664-a1de-dd889f884dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, pipeline\n",
    "tokenizerRRR= AutoTokenizer.from_pretrained(\"models/cmakea\" )\n",
    "modelLLL = TFAutoModelForSequenceClassification.from_pretrained(\"models/cmakea\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280dfbba-2d59-4333-83de-8ab3b5386c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpYOU = pipeline(\"text-classification\",model=modelLLL, tokenizer=tokenizerRRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7cd14-e664-4e51-8eb0-4dd06e5dab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlpYOU(\"Alad'2 est clairement le meilleur film de l'année 2018.\")) # POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa117ba8-37cb-4ed1-9add-0d76c237e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(text):\n",
    "    if text == '':\n",
    "        return(None)\n",
    "    else : \n",
    "        t = nlpYOU(text)\n",
    "        return(int(t[0]['label'][0]))\n",
    "    #t = get_proba(text)\n",
    "    #return(sum([t[i]*(i+1) for i in range(5)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6385e098-c01e-4f06-8a8b-0291e81331a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = sample[\"Commentaire général entretien : Collaborateur\"].apply(lambda text:get_score(preprocessing(text))).values\n",
    "score = sample[\"true score\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba13e9a-5f0a-4038-a132-90947ba7f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0 \n",
    "for i in range(len(score)):\n",
    "    if np.abs(score[i]-level[i])<=1:\n",
    "        c+=1\n",
    "print(c/len(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6402ccc8-a12a-40c6-9255-06106ea84fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(score,level)\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Vraies étiquettes')\n",
    "plt.title('Matrice de Confusion pour le commentaire de colaborateur',fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965bd5e-da09-452c-beaf-436c633642cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyse de sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1075cca1-39df-44dd-893e-c3607fcd7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2dfa1-6f24-45e7-bece-eff748171084",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['general_entretien_collaborateur_score'] = train['Commentaire général entretien : Collaborateur'].apply(lambda text : get_score(preprocessing(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5c5db-0cbb-4db4-a6fe-07877f8176a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ff88b-96a4-41cc-a809-3886b2d6153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Matricule de l'évalué\",\"Matricule de l'évaluateur\",\"Commentaire général entretien : Collaborateur\",\"general_entretien_collaborateur_score\"]].to_csv('data/sentiment_analyse_entretien_collaborateur.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b71d466-bcf8-44f2-9f76-8d7e92e77ff0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyse de résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcebfb3-2471-4272-8e3c-5c151d9e7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sentiment_analyse_entretien_collaborateur.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33144378-b1bf-4a76-856f-1d44ce0926fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693a104-35e0-4f42-8528-461029243a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166f239-cf59-4c3b-a482-209102f5daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"general_entretien_collaborateur_score\")\n",
    "plt.title(f'general_entretien_collaborateur_score')\n",
    "plt.xlabel(f'Score')\n",
    "plt.ylabel(\"Nombre d'occurrences\")\n",
    " \n",
    "# Afficher le graphique\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63afc18-33ea-48dc-a5b0-5aede288d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=stopwords.words('french')\n",
    "A.extend(['X', 'x','xxx','xx','ras','cet', 'ete', 'tres', 'non', 'oui', 'Non', 'Oui', 'a', 'A', 'tout', 'pu', 'faire', 'etre', 'sein',\n",
    "         'chez', 'lors', 'car', 'va', 'ainsi', 'fait', 'cette', 'afin', 'cela', 'avoir', 'cette', 'doit', 'avant', 'alors', \n",
    "         'autre', 'chaque', 'tel', 'tels', 'tellement', 'font', 'bien', 'peu', 'aussi', 'temps', 'tant', 'toute', 'toutes', 'ci', \n",
    "         'bon', 'alors', 'au', 'aucuns', 'aussi', 'autre' ,'avant', 'avec' ,'avoir', 'bon' ,'car', 'ce', 'ces', 'ceux', 'chaque',\n",
    "          'comme',\n",
    "         'comment', 'dans', 'des', 'du', 'dedans','dehors', 'depuis', 'devrait', 'doit', 'donc', 'dos', 'début', 'elle',\n",
    "          'elles', 'en', 'encore',\n",
    "          'essai', 'est', 'et', 'eu',  'fait', 'faites', 'fois', 'font', 'hors', 'ici', 'il', 'ils','ca',\n",
    "         'je', 'juste' ,'la', 'le', 'les', 'leur', 'là', 'ma' ,'maintenant', 'mais', 'mes', 'mien', 'moins', 'mon', 'mot', 'même','egalement'\n",
    "          'ni', 'nommés', 'notre' ,'nous', 'ou', 'où', 'par' ,'parce' ,'pas', 'peux', 'cas',\n",
    "          'peut', 'peu', 'plupart', 'pour', 'pourquoi', 'quand', 'que', 'quel' ,'quelle', 'quelles', 'quels' ,'qui', 'sa', 'sans', 'ses', 'seulement', 'si',\n",
    "          'sien', 'son', 'ont' ,'sous', \n",
    "          'soyez' ,'sujet', 'sur', 'ta', 'tandis', 'tellement' ,'tels', 'tes', 'ton', 'tous', 'tout', 'trop', 'tres', 'tu', 'voient', 'vont', 'votre', 'vous',\n",
    "         'vu', 'ça', 'étaient', 'etat', 'étions', 'ete', 'etre', 'entre', 'beaucoup', 'jour', 'annees','annee' 'plus', 'trouve', 'meme', 'dont', 'vue', 'nan','toujours','concernant','plus'])\n",
    "  \n",
    "def enleve_stop_words(text):\n",
    "    words = text.split(\" \")\n",
    "    words_net= [item for item in words if item not in A] \n",
    "    return(\" \".join(words_net))\n",
    "\n",
    "def preprocessing(text,stop_words = True):\n",
    "    if isinstance(text, str):\n",
    "        text = str(text)\n",
    "        #lowercase\n",
    "        text = text.lower()\n",
    "        #accents and punctuations\n",
    "        text = re.sub(\"\\d+\", \" \", text) #numbers normalization\n",
    "        if stop_words:\n",
    "            text = enleve_stop_words(text)\n",
    "        text = re.sub('[éèê]', \"e\", text) #accents removal\n",
    "        text = re.sub(\"[.,;:!?]\", \" \", text)\n",
    "        text = re.sub(\"[|{}\\[\\]()«»/]\", \" \", text)\n",
    "        text = re.sub(\"[“”]\", \" \", text)\n",
    "        text = re.sub(\"'\", \" \", text) \n",
    "        text = re.sub(\"\", \" \", text) \n",
    "        text = re.sub('\"', \" \", text)\n",
    "        text = re.sub('[+-]', \" \", text)\n",
    "        text = re.sub('[=*/]', \" \", text)\n",
    "        text = re.sub(\"ô\", \"o\", text)\n",
    "        text = re.sub(\"°\", \"\", text)\n",
    "        text = re.sub(\"\\x80\", \"\", text)\n",
    "        text = re.sub(\"[«»€$%;:.,?!=()+&@*%^¨~#><]{1,}\", \" \", text)\n",
    "        text = re.sub(\"[\\/]{1,}\", \" \", text)\n",
    "        text = re.sub(\"'\", \" \", text)\n",
    "        text = re.sub('\"', \" \", text)\n",
    "        #Symbols\n",
    "        text = re.sub(\"[€%$£]\", \"\", text)\n",
    "        #End of lines and parahraph breaks\n",
    "        text = re.sub('\\r\\n', \" \", text)\n",
    "        text = re.sub('\\n', \" \", text) #end of line removal\n",
    "        #white spaces\n",
    "        text = re.sub('\\s+', \" \", text) #white space removal\n",
    "        text = text.rstrip(\" \") #à droite\n",
    "        text = text.lstrip(\" \") #à gauche\n",
    "        if stop_words:\n",
    "            text = enleve_stop_words(text)\n",
    "    else:\n",
    "        return('')\n",
    "    return  text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0743f0-c0ac-453f-a1e6-94635c8c8b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    Deconnexion_pro_perso= df[\"Commentaire général entretien : Collaborateur\"][df[\"general_entretien_collaborateur_score\"]==i].apply(lambda x:preprocessing(x)).apply(lambda x:str(x).split())\n",
    "    top = Counter([item for sublist in Deconnexion_pro_perso for item in sublist ])\n",
    "    temp = pd.DataFrame(top.most_common(10))\n",
    "    temp.columns = ['Common_words','count']\n",
    "    mots_a_supprimer = [\"entretien\",\"annee\",\"echange\",\"competence\",\"mission\"]\n",
    "\n",
    "    top = Counter({mot: top[mot] for mot in  top if mot not in mots_a_supprimer})\n",
    "\n",
    "    #fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words in Deconnexion/articulation column')\n",
    "    #fig.show()\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(top)\n",
    "\n",
    "    # Afficher le nuage de mots\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(\"Score \"+str(i))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ecf7c0-7dfb-4180-b1e5-84cfd0cad6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce69fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=pd.read_csv('supported_python_librairies.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2291d768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- --------------------\n",
      "alabaster                     0.7.12\n",
      "anaconda-client               1.11.0\n",
      "anaconda-navigator            2.3.2\n",
      "anaconda-project              0.11.1\n",
      "annotated-types               0.7.0\n",
      "anyio                         3.5.0\n",
      "appdirs                       1.4.4\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "arrow                         1.2.2\n",
      "asgiref                       3.6.0\n",
      "astroid                       2.11.7\n",
      "astropy                       5.1\n",
      "atomicwrites                  1.4.0\n",
      "attrs                         21.4.0\n",
      "Automat                       20.2.0\n",
      "autopep8                      1.6.0\n",
      "Babel                         2.9.1\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "backports.tempfile            1.0\n",
      "backports.weakref             1.0.post1\n",
      "bcrypt                        3.2.0\n",
      "beautifulsoup4                4.11.1\n",
      "binaryornot                   0.4.4\n",
      "bitarray                      2.5.1\n",
      "bkcharts                      0.2\n",
      "black                         22.6.0\n",
      "bleach                        4.1.0\n",
      "blis                          0.7.11\n",
      "bokeh                         2.4.3\n",
      "boto3                         1.24.28\n",
      "botocore                      1.27.28\n",
      "Bottleneck                    1.3.5\n",
      "Brotli                        1.1.0\n",
      "brotlipy                      0.7.0\n",
      "catalogue                     2.0.10\n",
      "certifi                       2022.9.14\n",
      "cffi                          1.15.1\n",
      "chardet                       4.0.0\n",
      "charset-normalizer            2.0.4\n",
      "click                         8.0.4\n",
      "click-plugins                 1.1.1\n",
      "cligj                         0.7.2\n",
      "cloudpathlib                  0.18.1\n",
      "cloudpickle                   2.0.0\n",
      "clyent                        1.2.2\n",
      "colorama                      0.4.6\n",
      "colorcet                      3.0.0\n",
      "comtypes                      1.1.10\n",
      "conda                         22.9.0\n",
      "conda-build                   3.22.0\n",
      "conda-content-trust           0.1.3\n",
      "conda-pack                    0.6.0\n",
      "conda-package-handling        1.9.0\n",
      "conda-repo-cli                1.0.20\n",
      "conda-token                   0.4.0\n",
      "conda-verify                  3.4.2\n",
      "confection                    0.1.5\n",
      "constantly                    15.1.0\n",
      "contourpy                     1.2.1\n",
      "cookiecutter                  1.7.3\n",
      "cryptography                  37.0.1\n",
      "cssselect                     1.1.0\n",
      "cycler                        0.11.0\n",
      "cymem                         2.0.8\n",
      "Cython                        0.29.32\n",
      "cytoolz                       0.11.0\n",
      "daal4py                       2021.6.0\n",
      "dash                          2.16.1\n",
      "dash-bootstrap-components     1.3.1\n",
      "dash-colorscales              0.0.4\n",
      "dash-core-components          2.0.0\n",
      "dash-daq                      0.5.0\n",
      "dash-html-components          2.0.0\n",
      "dash-table                    5.0.0\n",
      "dask                          2022.7.0\n",
      "datashader                    0.14.1\n",
      "datashape                     0.5.4\n",
      "debugpy                       1.5.1\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "diff-match-patch              20200713\n",
      "dill                          0.3.4\n",
      "distributed                   2022.7.0\n",
      "Django                        4.2.1\n",
      "docutils                      0.18.1\n",
      "dtale                         3.11.0\n",
      "entrypoints                   0.4\n",
      "et-xmlfile                    1.1.0\n",
      "fastjsonschema                2.16.2\n",
      "filelock                      3.6.0\n",
      "fiona                         1.9.6\n",
      "flake8                        4.0.1\n",
      "Flask                         1.1.2\n",
      "Flask-Compress                1.14\n",
      "flask-ngrok                   0.0.25\n",
      "fonttools                     4.25.0\n",
      "fsspec                        2022.7.1\n",
      "future                        0.18.2\n",
      "gensim                        4.1.2\n",
      "geopandas                     0.14.3\n",
      "glob2                         0.7\n",
      "greenlet                      1.1.1\n",
      "h5py                          3.7.0\n",
      "HeapDict                      1.0.1\n",
      "holoviews                     1.15.0\n",
      "hvplot                        0.8.0\n",
      "hyperlink                     21.0.0\n",
      "idna                          3.3\n",
      "imagecodecs                   2021.8.26\n",
      "imageio                       2.19.3\n",
      "imagesize                     1.4.1\n",
      "importlib-metadata            4.11.3\n",
      "incremental                   21.3.0\n",
      "inflection                    0.5.1\n",
      "iniconfig                     1.1.1\n",
      "intake                        0.6.5\n",
      "intel-openmp                  2021.4.0\n",
      "intervaltree                  3.1.0\n",
      "ipykernel                     6.15.2\n",
      "ipython                       7.31.1\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    7.6.5\n",
      "isort                         5.9.3\n",
      "itemadapter                   0.3.0\n",
      "itemloaders                   1.0.4\n",
      "itsdangerous                  2.0.1\n",
      "jdcal                         1.4.1\n",
      "jedi                          0.18.1\n",
      "jellyfish                     0.9.0\n",
      "Jinja2                        2.11.3\n",
      "jinja2-time                   0.2.0\n",
      "jmespath                      0.10.0\n",
      "joblib                        1.1.0\n",
      "json5                         0.9.6\n",
      "jsonschema                    4.16.0\n",
      "jupyter                       1.0.0\n",
      "jupyter_client                7.3.4\n",
      "jupyter-console               6.4.3\n",
      "jupyter_core                  4.11.1\n",
      "jupyter-server                1.18.1\n",
      "jupyterlab                    3.4.4\n",
      "jupyterlab-pygments           0.1.2\n",
      "jupyterlab-server             2.10.3\n",
      "jupyterlab-widgets            1.0.0\n",
      "kaleido                       0.2.1\n",
      "keyring                       23.4.0\n",
      "kiwisolver                    1.4.2\n",
      "langcodes                     3.4.0\n",
      "language_data                 1.2.0\n",
      "lazy-object-proxy             1.6.0\n",
      "libarchive-c                  2.9\n",
      "llvmlite                      0.38.0\n",
      "locket                        1.0.0\n",
      "lxml                          4.9.1\n",
      "lz4                           3.1.3\n",
      "marisa-trie                   1.2.0\n",
      "Markdown                      3.3.4\n",
      "markdown-it-py                3.0.0\n",
      "MarkupSafe                    2.0.1\n",
      "matplotlib                    3.5.2\n",
      "matplotlib-inline             0.1.6\n",
      "mccabe                        0.6.1\n",
      "mdurl                         0.1.2\n",
      "menuinst                      1.4.19\n",
      "missingno                     0.5.2\n",
      "mistune                       0.8.4\n",
      "mkl                           2021.4.0\n",
      "mkl-fft                       1.3.1\n",
      "mkl-random                    1.2.2\n",
      "mkl-service                   2.4.0\n",
      "mock                          4.0.3\n",
      "mpmath                        1.2.1\n",
      "msgpack                       1.0.3\n",
      "multipledispatch              0.6.0\n",
      "munkres                       1.1.4\n",
      "murmurhash                    1.0.10\n",
      "mypy-extensions               0.4.3\n",
      "mysql-connector-python        8.0.33\n",
      "navigator-updater             0.3.0\n",
      "nbclassic                     0.3.5\n",
      "nbclient                      0.5.13\n",
      "nbconvert                     6.4.4\n",
      "nbformat                      5.5.0\n",
      "nest-asyncio                  1.5.5\n",
      "networkx                      2.8.4\n",
      "nltk                          3.7\n",
      "nose                          1.3.7\n",
      "notebook                      6.4.12\n",
      "numba                         0.55.1\n",
      "numexpr                       2.8.3\n",
      "numpy                         1.21.5\n",
      "numpydoc                      1.4.0\n",
      "olefile                       0.46\n",
      "openpyxl                      3.0.10\n",
      "packaging                     21.3\n",
      "pandas                        1.4.4\n",
      "pandas-bokeh                  0.5.5\n",
      "pandocfilters                 1.5.0\n",
      "panel                         0.13.1\n",
      "param                         1.12.0\n",
      "paramiko                      2.8.1\n",
      "parsel                        1.6.0\n",
      "parso                         0.8.3\n",
      "partd                         1.2.0\n",
      "pathlib                       1.0.1\n",
      "pathspec                      0.9.0\n",
      "patsy                         0.5.2\n",
      "pep8                          1.7.1\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "pika                          1.3.1\n",
      "Pillow                        9.2.0\n",
      "pip                           22.2.2\n",
      "pkginfo                       1.8.2\n",
      "platformdirs                  2.5.2\n",
      "plotly                        5.9.0\n",
      "pluggy                        1.0.0\n",
      "poyo                          0.5.0\n",
      "preshed                       3.0.9\n",
      "prometheus-client             0.14.1\n",
      "prompt-toolkit                3.0.20\n",
      "Protego                       0.1.16\n",
      "psutil                        5.9.0\n",
      "ptyprocess                    0.7.0\n",
      "py                            1.11.0\n",
      "pyasn1                        0.4.8\n",
      "pyasn1-modules                0.2.8\n",
      "pycodestyle                   2.8.0\n",
      "pycosat                       0.6.3\n",
      "pycparser                     2.21\n",
      "pyct                          0.4.8\n",
      "pycurl                        7.45.1\n",
      "pydantic                      2.7.4\n",
      "pydantic_core                 2.18.4\n",
      "PyDispatcher                  2.0.5\n",
      "pydocstyle                    6.1.1\n",
      "pyerfa                        2.0.0\n",
      "pyflakes                      2.4.0\n",
      "Pygments                      2.18.0\n",
      "PyHamcrest                    2.0.2\n",
      "PyJWT                         2.4.0\n",
      "pylint                        2.14.5\n",
      "pyls-spyder                   0.4.0\n",
      "PyNaCl                        1.5.0\n",
      "pyodbc                        4.0.34\n",
      "pyOpenSSL                     22.0.0\n",
      "pyparsing                     3.0.9\n",
      "pyproj                        3.6.1\n",
      "pyrsistent                    0.18.0\n",
      "PySocks                       1.7.1\n",
      "pytest                        7.1.2\n",
      "python-dateutil               2.8.2\n",
      "python-lsp-black              1.0.0\n",
      "python-lsp-jsonrpc            1.0.0\n",
      "python-lsp-server             1.3.3\n",
      "python-slugify                5.0.2\n",
      "python-snappy                 0.6.0\n",
      "pytz                          2022.1\n",
      "pyviz-comms                   2.0.2\n",
      "PyWavelets                    1.3.0\n",
      "pywin32                       302\n",
      "pywin32-ctypes                0.2.0\n",
      "pywinpty                      2.0.2\n",
      "PyYAML                        6.0\n",
      "pyzmq                         23.2.0\n",
      "QDarkStyle                    3.0.2\n",
      "qstylizer                     0.1.10\n",
      "QtAwesome                     1.0.3\n",
      "qtconsole                     5.2.2\n",
      "QtPy                          2.2.0\n",
      "queuelib                      1.5.0\n",
      "regex                         2022.7.9\n",
      "requests                      2.28.1\n",
      "requests-file                 1.5.1\n",
      "retrying                      1.3.4\n",
      "rich                          13.7.1\n",
      "rope                          0.22.0\n",
      "Rtree                         0.9.7\n",
      "ruamel-yaml-conda             0.15.100\n",
      "s3transfer                    0.6.0\n",
      "scikit-image                  0.19.2\n",
      "scikit-learn                  1.0.2\n",
      "scikit-learn-intelex          2021.20221004.171935\n",
      "scipy                         1.9.1\n",
      "Scrapy                        2.6.2\n",
      "seaborn                       0.11.2\n",
      "Send2Trash                    1.8.0\n",
      "service-identity              18.1.0\n",
      "setuptools                    63.4.1\n",
      "shapely                       2.0.4\n",
      "shellingham                   1.5.4\n",
      "sip                           4.19.13\n",
      "six                           1.16.0\n",
      "smart-open                    5.2.1\n",
      "sniffio                       1.2.0\n",
      "snowballstemmer               2.2.0\n",
      "sortedcollections             2.1.0\n",
      "sortedcontainers              2.4.0\n",
      "soupsieve                     2.3.1\n",
      "spacy                         3.7.5\n",
      "spacy-legacy                  3.0.12\n",
      "spacy-loggers                 1.0.5\n",
      "Sphinx                        5.0.2\n",
      "sphinxcontrib-applehelp       1.0.2\n",
      "sphinxcontrib-devhelp         1.0.2\n",
      "sphinxcontrib-htmlhelp        2.0.0\n",
      "sphinxcontrib-jsmath          1.0.1\n",
      "sphinxcontrib-qthelp          1.0.3\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "spyder                        5.2.2\n",
      "spyder-kernels                2.2.1\n",
      "SQLAlchemy                    1.4.39\n",
      "sqlparse                      0.4.4\n",
      "squarify                      0.4.3\n",
      "srsly                         2.4.8\n",
      "statsmodels                   0.13.2\n",
      "strsimpy                      0.2.1\n",
      "sympy                         1.10.1\n",
      "tables                        3.6.1\n",
      "tabulate                      0.8.10\n",
      "tbb                           2021.12.0\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.0.1\n",
      "terminado                     0.13.1\n",
      "testpath                      0.6.0\n",
      "text-unidecode                1.3\n",
      "textdistance                  4.2.1\n",
      "thinc                         8.2.4\n",
      "threadpoolctl                 2.2.0\n",
      "three-merge                   0.1.1\n",
      "tifffile                      2021.7.2\n",
      "tinycss                       0.4\n",
      "tldextract                    3.2.0\n",
      "toml                          0.10.2\n",
      "tomli                         2.0.1\n",
      "tomlkit                       0.11.1\n",
      "toolz                         0.11.2\n",
      "torch                         2.3.1\n",
      "tornado                       6.1\n",
      "tqdm                          4.64.1\n",
      "traitlets                     5.1.1\n",
      "Twisted                       22.2.0\n",
      "twisted-iocpsupport           1.0.2\n",
      "typer                         0.12.3\n",
      "typing_extensions             4.12.2\n",
      "tzdata                        2023.3\n",
      "ujson                         5.4.0\n",
      "Unidecode                     1.2.0\n",
      "urllib3                       1.26.11\n",
      "w3lib                         1.21.0\n",
      "wasabi                        1.1.3\n",
      "watchdog                      2.1.6\n",
      "wcwidth                       0.2.5\n",
      "weasel                        0.4.1\n",
      "webencodings                  0.5.1\n",
      "websocket-client              0.58.0\n",
      "Werkzeug                      2.0.3\n",
      "wheel                         0.37.1\n",
      "widgetsnbextension            3.5.2\n",
      "win-inet-pton                 1.1.0\n",
      "win-unicode-console           0.5\n",
      "wincertstore                  0.2\n",
      "wordcloud                     1.9.3\n",
      "wrapt                         1.14.1\n",
      "xarray                        0.20.1\n",
      "xlrd                          2.0.1\n",
      "XlsxWriter                    3.0.3\n",
      "xlwings                       0.27.15\n",
      "yapf                          0.31.0\n",
      "zict                          2.1.0\n",
      "zipp                          3.8.0\n",
      "zope.interface                5.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac0a3bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
      "     ---------------------------------------- 9.4/9.4 MB 6.5 MB/s eta 0:00:00\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 8.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.3-cp39-none-win_amd64.whl (287 kB)\n",
      "     -------------------------------------- 287.9/287.9 kB 6.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "     -------------------------------------- 417.5/417.5 kB 8.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\poste\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "     -------------------------------------- 177.6/177.6 kB 5.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\poste\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed fsspec-2024.6.1 huggingface-hub-0.24.5 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.43.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\POSTE\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\POSTE\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adac8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Différents imports\n",
    "\n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984327e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du texte à traiter\n",
    "\n",
    "\n",
    "\n",
    "text = \"\"\"I ordered a used book from your online site. \\\n",
    "\n",
    "The book is Les mystères de Paris from Victor Hugo. \\\n",
    "\n",
    "It was indicated on the site that it was in good condition. \\\n",
    "\n",
    "I received it a week after ordering. \\\n",
    "\n",
    "And while unpacking the package I realized that it was damaged (damaged pages, writings). \\\n",
    "\n",
    "I contacted customer service who proceeded to the immediate refund.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219f14bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-base and revision 686f1db (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746e36b8016049069a12d8d76049cc60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e591b821f28d4790bf7db6b6b1c2e667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534bda922977492dba397ccda2e790d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480ec19bbc504b8f80fc1d65d7b2178e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19156112b344ed5963fc4348e9e7067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'ai commandé un livre d'occasion à partir de votre site en ligne. Le livre est Les mystères de Paris de Victor Hugo. Il était indiqué sur le site qu'il était en bon état. J'ai reçu le livre une semaine après avoir commandé et alors que je déballais le paquet, je me suis rendu compte qu'il était endommagé (pages endommagées, écrits).\n"
     ]
    }
   ],
   "source": [
    "# Traduction\n",
    "\n",
    "\n",
    "\n",
    "translator = pipeline('translation_en_to_fr')\n",
    "\n",
    "outputs = translator(text, clean_up_tokenization_spaces=True, min_length=100)\n",
    "\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35037626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4550e68d6e4c66929422e895077add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209edb978a3548b485dd54626ad9c6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986cfd75b65247919050f2ddcab14586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a21906e59442f19d4e038648b3bac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.998112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  NEGATIVE  0.998112"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Classification\n",
    "\n",
    "\n",
    "\n",
    "classifier = pipeline(\"text-classification\")\n",
    "\n",
    "outputs = classifier(text)\n",
    "\n",
    "pd.DataFrame(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8336706f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f567b50049184528aa8271bd5f1c23ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac1ba189585481aab239d3a22299213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff79c4146c4241f0a811d7baa506aaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f6f0f93a5f44d49f071b84009ba47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.978184</td>\n",
       "      <td>Les mystères de Paris</td>\n",
       "      <td>58</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.900909</td>\n",
       "      <td>Victor Hugo</td>\n",
       "      <td>85</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score                   word  start  end\n",
       "0         MISC  0.978184  Les mystères de Paris     58   79\n",
       "1          PER  0.900909            Victor Hugo     85   96"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name Entity Recognition\n",
    "\n",
    "\n",
    "\n",
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "\n",
    "outputs = ner_tagger(text)\n",
    "\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f5bb2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.999558</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999614</td>\n",
       "      <td>Florida</td>\n",
       "      <td>68</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.999508</td>\n",
       "      <td>Bill</td>\n",
       "      <td>92</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score          word  start  end\n",
       "0          PER  0.999558  Donald Trump      0   12\n",
       "1          LOC  0.999614       Florida     68   75\n",
       "2          PER  0.999508          Bill     92   96"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "\n",
    "outputs = ner_tagger(\"Donald Trump, the former president, is now playing golf all days in Florida with his friend Bill\")\n",
    "\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad883cf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2237135414.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\POSTE\\AppData\\Local\\Temp\\ipykernel_12160\\2237135414.py\"\u001b[1;36m, line \u001b[1;32m15\u001b[0m\n\u001b[1;33m    outputs = reader(question=question, context=text)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Question Answering\n",
    "\n",
    "\n",
    "\n",
    "reader = pipeline(\"question-answering\")\n",
    "\n",
    "results = []\n",
    "\n",
    "questions = [\"What was ordered?\",\n",
    "\n",
    "\"What did the customer service?\"]\n",
    "\n",
    "for question in questions:\n",
    "\n",
    "outputs = reader(question=question, context=text)\n",
    "\n",
    "results.append(outputs)\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72072cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9a909de21748759983b88dc13fdf60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef49b15249314f7485628823ad64dfaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a78219b25c049289bd1275d13dcb08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c39301c8ea74dc38ca1a061ab9fa740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a062ba678d47cea0b0b961b5170d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 150, but your input_length is only 86. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The book is Les mystères de Paris from Victor Hugo. It was indicated on the site that it was in good condition. But while unpacking the package I realized it was damaged (damaged pages, writings) I contacted customer service who proceeded to the immediate refund.\n"
     ]
    }
   ],
   "source": [
    "# Summarization\n",
    "\n",
    "\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "outputs = summarizer(text, max_length=150, clean_up_tokenization_spaces=True)\n",
    "\n",
    "print(outputs[0]['summary_text'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dde177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32d1397e0ca45b7bc41792e071e0efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8050257699534cb48504a240ed2192f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941a359aa3d64373ab243aa5d413a036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8d680a1f8a45ed99b8643da293917c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf40bb581b3b4f00a52a22823b382971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ff1cb1a7c3441e81f2e0efce44df39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beef5f25f614434c86a161e06b6d9ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ordered a used book from your online site. \n",
      "The book is Les mystères de Paris from Victor Hugo. \n",
      "It was indicated on the site that it was in good condition. \n",
      "I received it a week after ordering. \n",
      "And while unpacking the package I realized that it was damaged (damaged pages, writings). \n",
      "I contacted customer service who proceeded to the immediate refund.\n",
      "\n",
      "Story I told to my friends:\n",
      "\n",
      "Dear friends. Let me tell you my last experience with this online store where I ordered a book. I ordered it on my computer a week before Christmas. \n",
      "\n",
      "It was in good condition but the title, it contains several books containing a very large amount of material with some essays and many short passages. \n",
      "\n",
      "What could say this guy should know better?\n",
      "\n",
      "And my question is: What did I bring with me here for a purchase, that we can understand? \n",
      "\n",
      "And what happened to them\n"
     ]
    }
   ],
   "source": [
    "# Text Generation\n",
    "\n",
    "\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "\n",
    "response = \"Dear friends. Let me tell you my last experience with this online store where I ordered a book.\"\n",
    "\n",
    "prompt = text + \"\\n\\nStory I told to my friends:\\n\\n\" + response\n",
    "\n",
    "outputs = generator(prompt, max_length=200)\n",
    "\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321eb302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qualité de vie au travailbien-êtreéquilibre vie pro/vie persostresscharge de travailenvironnement de travailflexibilitéconditions de travail']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"qualité de vie au travail\"\n",
    "\"bien-être\"\n",
    "\"équilibre vie pro/vie perso\"\n",
    "\"stress\"\n",
    "\"charge de travail\"\n",
    "\"environnement de travail\"\n",
    "\"flexibilité\"\n",
    "\"conditions de travail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61d3a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentaires</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Je trouve que la qualité de vie au travail est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L'équilibre entre vie professionnelle et perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Les conditions de travail sont stressantes et ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La rémunération est correcte, mais je manque d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        commentaires\n",
       "0  Je trouve que la qualité de vie au travail est...\n",
       "1  L'équilibre entre vie professionnelle et perso...\n",
       "2  Les conditions de travail sont stressantes et ...\n",
       "3  La rémunération est correcte, mais je manque d..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Exemples de commentaires dans la colonne 'commentaires'\n",
    "data = {'commentaires': [\n",
    "    \"Je trouve que la qualité de vie au travail est très bonne, mais la rémunération est trop faible.\",\n",
    "    \"L'équilibre entre vie professionnelle et personnelle est bon, mais le stress est élevé.\",\n",
    "    \"Les conditions de travail sont stressantes et la charge de travail est trop importante.\",\n",
    "    \"La rémunération est correcte, mais je manque de flexibilité dans mon emploi du temps.\"\n",
    "]}\n",
    "\n",
    "# Création d'un DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96425d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste de mots-clés associés à la qualité de vie au travail\n",
    "qvt_keywords = [\n",
    "    r'\\bqualité de vie au travail\\b', r'\\bbien-être\\b', r'\\béquilibre\\b', \n",
    "    r'\\bstress\\b', r'\\bcharge de travail\\b', r'\\benvironnement de travail\\b',\n",
    "    r'\\bflexibilité\\b', r'\\bconditions de travail\\b'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec06abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les parties du commentaire qui contiennent des mots-clés QVT\n",
    "def extract_qvt(comment):\n",
    "    # Regrouper tous les mots-clés sous une seule expression régulière\n",
    "    pattern = '|'.join(qvt_keywords)\n",
    "    # Trouver toutes les correspondances de QVT dans le commentaire\n",
    "    matches = re.findall(pattern, comment, flags=re.IGNORECASE)\n",
    "    if matches:\n",
    "        return comment  # Renvoie tout le commentaire si un mot-clé est trouvé\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cb03f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer l'extraction sur la colonne 'commentaires'\n",
    "df['commentaires_QVT'] = df['commentaires'].apply(extract_qvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e87c7fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        commentaires  \\\n",
      "0  Je trouve que la qualité de vie au travail est...   \n",
      "1  L'équilibre entre vie professionnelle et perso...   \n",
      "2  Les conditions de travail sont stressantes et ...   \n",
      "3  La rémunération est correcte, mais je manque d...   \n",
      "\n",
      "                                    commentaires_QVT  \n",
      "0  Je trouve que la qualité de vie au travail est...  \n",
      "1  L'équilibre entre vie professionnelle et perso...  \n",
      "2  Les conditions de travail sont stressantes et ...  \n",
      "3  La rémunération est correcte, mais je manque d...  \n"
     ]
    }
   ],
   "source": [
    "print(df[['commentaires', 'commentaires_QVT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "946c8a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        commentaires  \\\n",
      "0  Je trouve que la qualité de vie au travail est...   \n",
      "1  L'équilibre entre vie professionnelle et perso...   \n",
      "2  Les conditions de travail sont stressantes et ...   \n",
      "3  La rémunération est correcte, mais je manque d...   \n",
      "\n",
      "                               commentaires_QVT_part  \n",
      "0  Je trouve que la qualité de vie au travail est...  \n",
      "1  L'équilibre entre vie professionnelle et perso...  \n",
      "2  Les conditions de travail sont stressantes et ...  \n",
      "3  La rémunération est correcte, mais je manque d...  \n"
     ]
    }
   ],
   "source": [
    "#Si tu veux extraire uniquement une portion spécifique du commentaire (autour du mot-clé), tu peux adapter l'extraction comme suit :\n",
    "#\n",
    "def extract_qvt_part(comment):\n",
    "    # Regrouper tous les mots-clés sous une seule expression régulière\n",
    "    pattern = '|'.join(qvt_keywords)\n",
    "    # Trouver le premier match et extraire une portion autour du mot-clé\n",
    "    match = re.search(pattern, comment, flags=re.IGNORECASE)\n",
    "    if match:\n",
    "        start = max(0, match.start() - 50)  # Extraire 50 caractères avant le mot-clé\n",
    "        end = min(len(comment), match.end() + 50)  # Extraire 50 caractères après le mot-clé\n",
    "        return comment[start:end]\n",
    "    return None\n",
    "\n",
    "# Appliquer l'extraction sur la colonne 'commentaires'\n",
    "df['commentaires_QVT_part'] = df['commentaires'].apply(extract_qvt_part)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(df[['commentaires', 'commentaires_QVT_part']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45b2eea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        commentaires  \\\n",
      "0  Équilibre vie pro/vie perso: bon | Qualité de ...   \n",
      "1  Équilibre: difficile | QVT: stressant | Rémuné...   \n",
      "2  Vie personnelle impactée | Bien-être au travai...   \n",
      "3  Équilibre correct | Conditions de travail médi...   \n",
      "\n",
      "                           commentaires_QVT  \n",
      "0  Qualité de vie au travail: satisfaisante  \n",
      "1                            QVT: stressant  \n",
      "2           Bien-être au travail: excellent  \n",
      "3           Conditions de travail médiocres  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Exemple de DataFrame avec des commentaires séparés par une barre verticale '|'\n",
    "data = {'commentaires': [\n",
    "    \"Équilibre vie pro/vie perso: bon | Qualité de vie au travail: satisfaisante | Rémunération: moyenne\",\n",
    "    \"Équilibre: difficile | QVT: stressant | Rémunération: faible\",\n",
    "    \"Vie personnelle impactée | Bien-être au travail: excellent | Salaire correct\",\n",
    "    \"Équilibre correct | Conditions de travail médiocres | Salaire insuffisant\"\n",
    "]}\n",
    "\n",
    "# Création d'un DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Séparateur utilisé dans les commentaires (ici la barre verticale '|')\n",
    "separateur = '|'\n",
    "\n",
    "# Séparer chaque commentaire en fonction du séparateur\n",
    "df['commentaire_parts'] = df['commentaires'].str.split(separateur)\n",
    "\n",
    "# Supposons que la qualité de vie au travail soit toujours la deuxième partie du commentaire (index 1)\n",
    "df['commentaires_QVT'] = df['commentaire_parts'].apply(lambda x: x[1].strip() if len(x) > 1 else None)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(df[['commentaires', 'commentaires_QVT']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b2ef730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        commentaires  \\\n",
      "0  Équilibre vie pro/vie perso: bon | Qualité de ...   \n",
      "1  Équilibre: difficile | QVT: stressant | Rémuné...   \n",
      "2  Vie personnelle impactée | Bien-être au travai...   \n",
      "3  Équilibre correct | Conditions de travail médi...   \n",
      "\n",
      "                           commentaires_QVT  \n",
      "0  Qualité de vie au travail: satisfaisante  \n",
      "1                            QVT: stressant  \n",
      "2           Bien-être au travail: excellent  \n",
      "3           Conditions de travail médiocres  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Liste de mots-clés associés à la qualité de vie au travail\n",
    "qvt_keywords = [\n",
    "    r'qualité de vie au travail', r'QVT', r'bien-être', r'conditions de travail'\n",
    "]\n",
    "\n",
    "# Fonction pour trouver la partie QVT après avoir séparé le commentaire\n",
    "def find_qvt_part(parts):\n",
    "    pattern = '|'.join(qvt_keywords)  # Fusionner les mots-clés en une seule expression régulière\n",
    "    for part in parts:\n",
    "        if re.search(pattern, part, flags=re.IGNORECASE):\n",
    "            return part.strip()  # Retourner la partie contenant un mot-clé\n",
    "    return None\n",
    "\n",
    "# Appliquer la fonction sur les parties du commentaire\n",
    "df['commentaires_QVT'] = df['commentaire_parts'].apply(find_qvt_part)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(df[['commentaires', 'commentaires_QVT']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abefeb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import pipeline\n",
    "\n",
    "# Charger un pipeline pour l'analyse de sentiment\n",
    "#sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Analyse de sentiment d'une phrase\n",
    "#result = sentiment_pipeline(\"I love using Hugging Face models!\")\n",
    "#print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26255674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Charger le modèle pré-entraîné\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "\n",
    "# Analyse de sentiment\n",
    "sentence = Sentence(\"Flair is pretty neat for sentiment analysis.\")\n",
    "classifier.predict(sentence)\n",
    "\n",
    "# Afficher le résultat\n",
    "print(sentence.labels)\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialiser l'analyseur\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Analyse de sentiment\n",
    "result = analyzer.polarity_scores(\"I love natural language processing!\")\n",
    "print(result)\n",
    "\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Analyse de texte\n",
    "doc = nlp(\"I am very happy with the results of my analysis!\")\n",
    "\n",
    "# Utilisation de TextBlob pour l'analyse de sentiment\n",
    "sentiment = TextBlob(doc.text).sentiment\n",
    "print(sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7701fd",
   "metadata": {},
   "source": [
    "Pour effectuer de l'analyse de sentiment, vous avez à disposition plusieurs modèles et bibliothèques. Si vous voulez des performances optimales, les modèles basés sur Transformers comme BERT ou RoBERTa sont idéaux. Pour des solutions plus simples et rapides à mettre en place, vous pouvez vous tourner vers des bibliothèques comme Flair, TextBlob, ou VADER. Le choix du modèle ou de la bibliothèque dépend de votre cas d'usage, de la langue et de la taille des données disponibles.\n",
    "\n",
    "\n",
    "GloVe, Word2Vec, et les embeddings (ou word embeddings) sont des techniques populaires en NLP (Natural Language Processing) pour représenter des mots sous forme de vecteurs numériques. Elles ont été utilisées avant l'émergence des modèles basés sur transformers comme BERT, mais elles sont toujours très utiles dans certaines applications. Voici une explication détaillée de chaque méthode et leur rôle dans des tâches comme l'analyse de sentiment.\n",
    "\n",
    "Applications en analyse de sentiment :\n",
    "\n",
    "Word2Vec produit des vecteurs de mots qui peuvent être utilisés comme entrée dans des modèles de machine learning pour des tâches comme l'analyse de sentiment.\n",
    "Cependant, Word2Vec génère des représentations statiques des mots : un mot a toujours la même représentation, quel que soit le contexte (ce qui est une limitation par rapport aux modèles comme BERT qui produisent des représentations contextuelles).\n",
    "Utilisation : Vous pouvez utiliser la bibliothèque Gensim pour charger des modèles Word2Vec pré-entraînés ou entraîner votre propre modèle.\n",
    "\n",
    "GloVe produit des embeddings statiques comme Word2Vec, mais il est particulièrement efficace pour capturer des relations sémantiques entre les mots.\n",
    "Il est souvent utilisé avec des modèles de machine learning comme les LSTM ou les réseaux de neurones pour des tâches de NLP.\n",
    "\n",
    "Conclusion\n",
    "Word2Vec et GloVe sont des techniques classiques de word embeddings qui produisent des représentations statiques des mots. Elles sont simples à utiliser et efficaces dans de nombreuses tâches de NLP, y compris l'analyse de sentiment.\n",
    "Les transformers comme BERT produisent des embeddings contextuels et surpassent généralement les techniques statiques dans des tâches comme l'analyse de sentiment, car ils prennent en compte le contexte complet dans lequel un mot apparaît.\n",
    "Embeddings comme ceux générés par Word2Vec et GloVe restent utiles dans des architectures plus simples ou lorsque les ressources de calcul sont limitées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Charger un modèle Word2Vec pré-entraîné\n",
    "model = Word2Vec.load(\"path_to_model\")\n",
    "\n",
    "# Accéder au vecteur d'un mot\n",
    "word_vector = model.wv['happy']\n",
    "print(word_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4722287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [Je trouve que le salaire est trop bas., J'app...\n",
      "1    [rémunération est logique., J'apprécie beaucou...\n",
      "Name: phrases, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\POSTE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Ce matin \n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# Télécharger le modèle de tokenisation de phrases si besoin\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Exemple de dataframe avec un commentaire par ligne\n",
    "df = pd.DataFrame({\n",
    "    'commentaires': [\n",
    "        \"Je trouve que le salaire est trop bas. J'apprécie beaucoup la flexibilité du télétravail. Concernant l'ambiance au bureau, je la trouve stressante.\",\n",
    "        \n",
    "    \"rémunération est logique. J'apprécie beaucoup les jours du télétravail. Concernant l'ambiance au travail, je la trouve parfaite.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Tokenizer pour diviser en phrases\n",
    "df['phrases'] = df['commentaires'].apply(nltk.sent_tokenize)\n",
    "\n",
    "print(df['phrases'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "257baa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         qualite_vie  \\\n",
      "0  Concernant l'ambiance au bureau, je la trouve ...   \n",
      "1  Concernant l'ambiance au travail, je la trouve...   \n",
      "\n",
      "                                           equilibre  \\\n",
      "0  J'apprécie beaucoup la flexibilité du télétrav...   \n",
      "1     J'apprécie beaucoup les jours du télétravail.    \n",
      "\n",
      "                              remuneration  \n",
      "0  Je trouve que le salaire est trop bas.   \n",
      "1               rémunération est logique.   \n"
     ]
    }
   ],
   "source": [
    "# Listes de mots-clés par thématique\n",
    "mots_qualite_vie = ['ambiance', 'conditions', 'environnement', 'stress', 'bien-être', 'collègues', 'bureau']\n",
    "mots_equilibre = ['horaires', 'famille', 'équilibre', 'télétravail', 'flexibilité', 'temps libre']\n",
    "mots_remuneration = ['salaire', 'prime', 'rémunération', 'augmentation', 'compensation', 'avantages']\n",
    "\n",
    "# Fonction pour classifier chaque phrase\n",
    "def classer_thematique(phrase):\n",
    "    phrase = phrase.lower()\n",
    "    if any(mot in phrase for mot in mots_qualite_vie):\n",
    "        return 'Qualité de vie au travail'\n",
    "    elif any(mot in phrase for mot in mots_equilibre):\n",
    "        return 'Équilibre vie professionnelle/personnelle'\n",
    "    elif any(mot in phrase for mot in mots_remuneration):\n",
    "        return 'Rémunération'\n",
    "    else:\n",
    "        return 'Inconnu'\n",
    "\n",
    "# Fonction pour traiter un commentaire et classifier ses phrases\n",
    "def classifier_commentaire(commentaire):\n",
    "    phrases = nltk.sent_tokenize(commentaire)\n",
    "    classes = {'Qualité de vie au travail': '', 'Équilibre vie professionnelle/personnelle': '', 'Rémunération': ''}\n",
    "    \n",
    "    for phrase in phrases:\n",
    "        thematique = classer_thematique(phrase)\n",
    "        if thematique != 'Inconnu':\n",
    "            classes[thematique] += phrase + ' '  # Ajouter la phrase à la bonne catégorie\n",
    "\n",
    "    return classes\n",
    "\n",
    "# Appliquer la fonction sur chaque commentaire\n",
    "df['classifications'] = df['commentaires'].apply(classifier_commentaire)\n",
    "\n",
    "# Extraire les phrases pour chaque thématique\n",
    "df['qualite_vie'] = df['classifications'].apply(lambda x: x['Qualité de vie au travail'])\n",
    "df['equilibre'] = df['classifications'].apply(lambda x: x['Équilibre vie professionnelle/personnelle'])\n",
    "df['remuneration'] = df['classifications'].apply(lambda x: x['Rémunération'])\n",
    "\n",
    "print(df[['qualite_vie', 'equilibre', 'remuneration']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "015fd9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentaires</th>\n",
       "      <th>phrases</th>\n",
       "      <th>classifications</th>\n",
       "      <th>qualite_vie</th>\n",
       "      <th>equilibre</th>\n",
       "      <th>remuneration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Je trouve que le salaire est trop bas. J'appré...</td>\n",
       "      <td>[Je trouve que le salaire est trop bas., J'app...</td>\n",
       "      <td>{'Qualité de vie au travail': 'Concernant l'am...</td>\n",
       "      <td>Concernant l'ambiance au bureau, je la trouve ...</td>\n",
       "      <td>J'apprécie beaucoup la flexibilité du télétrav...</td>\n",
       "      <td>Je trouve que le salaire est trop bas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rémunération est logique. J'apprécie beaucoup ...</td>\n",
       "      <td>[rémunération est logique., J'apprécie beaucou...</td>\n",
       "      <td>{'Qualité de vie au travail': 'Concernant l'am...</td>\n",
       "      <td>Concernant l'ambiance au travail, je la trouve...</td>\n",
       "      <td>J'apprécie beaucoup les jours du télétravail.</td>\n",
       "      <td>rémunération est logique.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        commentaires  \\\n",
       "0  Je trouve que le salaire est trop bas. J'appré...   \n",
       "1  rémunération est logique. J'apprécie beaucoup ...   \n",
       "\n",
       "                                             phrases  \\\n",
       "0  [Je trouve que le salaire est trop bas., J'app...   \n",
       "1  [rémunération est logique., J'apprécie beaucou...   \n",
       "\n",
       "                                     classifications  \\\n",
       "0  {'Qualité de vie au travail': 'Concernant l'am...   \n",
       "1  {'Qualité de vie au travail': 'Concernant l'am...   \n",
       "\n",
       "                                         qualite_vie  \\\n",
       "0  Concernant l'ambiance au bureau, je la trouve ...   \n",
       "1  Concernant l'ambiance au travail, je la trouve...   \n",
       "\n",
       "                                           equilibre  \\\n",
       "0  J'apprécie beaucoup la flexibilité du télétrav...   \n",
       "1     J'apprécie beaucoup les jours du télétravail.    \n",
       "\n",
       "                              remuneration  \n",
       "0  Je trouve que le salaire est trop bas.   \n",
       "1               rémunération est logique.   "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea2fec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9674bfb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74424b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7298096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c40e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dae17dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "                                        commentaires  cluster\n",
      "0  Le salaire est insuffisant pour la charge de t...        0\n",
      "1  Je suis satisfait de mon équilibre entre vie p...        2\n",
      "2     L'environnement de travail est très stressant.        1\n",
      "3   Je trouve les conditions de travail acceptables.        2\n",
      "4  La rémunération devrait être plus élevée pour ...        0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\POSTE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\POSTE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Lemmatisation\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem=WordNetLemmatizer()\n",
    "\n",
    "#Charger les stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "mots_vides=stopwords.words('english')\n",
    "print('\\n')\n",
    "print(mots_vides)\n",
    "\n",
    "# Exemple de dataframe avec des commentaires\n",
    "df = pd.DataFrame({\n",
    "    'commentaires': [\n",
    "        \"Le salaire est insuffisant pour la charge de travail.\",\n",
    "        \"Je suis satisfait de mon équilibre entre vie personnelle et professionnelle.\",\n",
    "        \"L'environnement de travail est très stressant.\",\n",
    "        \"Je trouve les conditions de travail acceptables.\",\n",
    "        \"La rémunération devrait être plus élevée pour le niveau de travail exigé.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# 1. Vectorisation des commentaires avec TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['commentaires'])\n",
    "\n",
    "# 2. Appliquer KMeans pour regrouper les commentaires\n",
    "n_clusters = 3  # Nombre de thématiques à identifier (qualité de vie, rémunération, équilibre)\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# 3. Analyse des clusters (manuellement)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40d2b8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aaeed0c6b85463a94c68ce801d2ad3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\POSTE\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\POSTE\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eaa3dd66de24abfbb199d93ec4814a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8c84cd89f7482dbb227264c3c23ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafd572dc0544e249018b5278b7b94bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed8e9d7cd6c4eb08aff0c6481bce1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Charger le modèle et le tokenizer BERT\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Encoder les commentaires avec BERT\n",
    "def encode_commentaire(commentaire):\n",
    "    inputs = tokenizer(commentaire, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "# Appliquer l'encodage BERT à tous les commentaires\n",
    "df['embeddings'] = df['commentaires'].apply(encode_commentaire)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Lemmatisation\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem=WordNetLemmatizer()\n",
    "\n",
    "#Charger les stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "mots_vides=stopwords.words('english')\n",
    "print('\\n')\n",
    "print(mots_vides)\n",
    "\n",
    "#Nettoyage de tweet\n",
    "#Pour manipuler des expressions regulieres\n",
    "import re\n",
    "#ponctuations\n",
    "import string\n",
    "ponctuations=list(string.punctuation)\n",
    "print(ponctuations)\n",
    "\n",
    "def clean_tweet(tweet,ponctuations,stopwords,lem):\n",
    "    #Harmonisation de la classe\n",
    "    temp=tweet.lower()\n",
    "    #retirer les contractions en anglais,les mentions ,les @ ,#,de liens web\n",
    "    temp=re.sub(\"'\",\"\",temp)\n",
    "    \n",
    "    #Retrait de la ponctuation\n",
    "    temp=\"\".join([char for char in list(temp) if not (char in ponctuations)])\n",
    "    #Retrait des nombres\n",
    "    \n",
    "    temp=re.sub(\"[0-9]\",\"\",temp)\n",
    "    \n",
    "    #Tokenization\n",
    "    \n",
    "    temp=word_tokenize(temp)\n",
    "    \n",
    "    #Lemmatisation\n",
    "    temp=[lem.lemmatize(mot) for mot in temp]\n",
    "    #Retrai de stopwords\n",
    "    \n",
    "    temp=[mot for mot in temp if mot not in stopwords]\n",
    "    #Retrait de tokens de moins de 3 caracteres\n",
    "    \n",
    "    temp=[mot for mot in temp if len(mot)>=3]\n",
    "    #Reformer la chaine\n",
    "    \n",
    "    temp=\" \".join(mot for mot in temp)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f2a4161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n",
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\POSTE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\POSTE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Lemmatisation\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem=WordNetLemmatizer()\n",
    "\n",
    "#Charger les stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "mots_vides=stopwords.words('french')\n",
    "print('\\n')\n",
    "print(mots_vides)\n",
    "\n",
    "#Nettoyage de tweet\n",
    "#Pour manipuler des expressions regulieres\n",
    "import re\n",
    "#ponctuations\n",
    "import string\n",
    "ponctuations=list(string.punctuation)\n",
    "print(ponctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcdc77f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    # Suppression des caractères spéciaux et de la ponctuation\n",
    "    processed_tweet = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    \n",
    "    # Conversion en minuscules\n",
    "    processed_tweet = processed_tweet.lower()\n",
    "    \n",
    "    # Tokenisation du texte\n",
    "    tokens = word_tokenize(processed_tweet)\n",
    "    \n",
    "    # Suppression des mots vides\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatisation des tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Joindre les tokens en une seule chaîne\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "# La Lemmatisation\n",
    "\n",
    "\n",
    "# Appliquer le nettoyage du texte sur la colonne 'texte'\n",
    "df['texte_nettoye'] = df['text'].apply(clean_text)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fcaf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour générer le word cloud\n",
    "def generer_wordcloud(tweets, titre):\n",
    "    tout_texte = ' '.join(tweets)\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(tout_texte)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(titre, fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Générer le word cloud \n",
    "generer_wordcloud(df['text'], 'Word Cloud - des tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd6f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# pour obtenir les mots les plus utilisés\n",
    "def get_maxtoken(tweets, num=30):\n",
    "  word_tokens = Counter(tweets)\n",
    "  max_common = word_tokens.most_common(num)\n",
    "  return dict(max_common)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
